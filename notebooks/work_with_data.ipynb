{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d51a7dd-f1f8-4447-9680-90b61ff9d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import h5py\n",
    "# не удалять! import hdf5plugin !\n",
    "import hdf5plugin\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50983244-4119-4536-9d8b-3404237f5854",
   "metadata": {},
   "source": [
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f238e7e9-9416-4999-95fb-9d85ba6736ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/metadata.csv'\n",
    "df_meta = pd.read_csv(meta_file, index_col='cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcae7984-d597-4764-98d1-d53638b3a550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>donor</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>technology</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e0dde41ed6f2</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>MasP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25b1de7f18f6</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>MkP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59e175749a4c</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>MkP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc43f415f240</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>NeuP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cf6cb48a1aca</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>HSC</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d03cdc2150c</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>EryP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ed27b16f6b29</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>NeuP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20a5293b5a5f</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>NeuP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9c110ee995b5</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>HSC</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655fb0bf81df</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>HSC</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              day  donor cell_type technology\n",
       "cell_id                                      \n",
       "e0dde41ed6f2    3  27678      MasP    citeseq\n",
       "25b1de7f18f6    3  27678       MkP    citeseq\n",
       "59e175749a4c    3  27678       MkP    citeseq\n",
       "cc43f415f240    3  27678      NeuP    citeseq\n",
       "cf6cb48a1aca    3  27678       HSC    citeseq\n",
       "7d03cdc2150c    3  27678      EryP    citeseq\n",
       "ed27b16f6b29    3  27678      NeuP    citeseq\n",
       "20a5293b5a5f    3  27678      NeuP    citeseq\n",
       "9c110ee995b5    3  27678       HSC    citeseq\n",
       "655fb0bf81df    3  27678       HSC    citeseq"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "599a3d0f-ec1b-4dda-aa8e-acfe6289fb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119191\n",
      "['e0dde41ed6f2', '25b1de7f18f6', '59e175749a4c', 'cc43f415f240', 'cf6cb48a1aca', '7d03cdc2150c', 'ed27b16f6b29', '20a5293b5a5f', '9c110ee995b5', '655fb0bf81df']\n"
     ]
    }
   ],
   "source": [
    "ids = list(df_meta[df_meta['technology'] == 'citeseq'].index)\n",
    "print(len(ids))\n",
    "print(ids[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde6280-6066-44fc-8aa5-dfbe66f8a887",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21986a06-adaf-4979-9e30-bc4e8852d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ids = pd.read_csv('/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/evaluation_ids.csv', index_col='cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292d1867-1213-445a-8b0a-78f831307426",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_multi_inputs.h5'\n",
    "my = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_multi_targets.h5'\n",
    "cx = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_cite_inputs.h5'\n",
    "cy = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_cite_targets.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a00cefa-c1b3-4ad3-b1f8-e555b19efa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_my = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/test_multi_inputs.h5'\n",
    "test_cy = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/test_cite_inputs.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a5d90e-922c-4141-91d4-d29d7bbe15c8",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b03b85f-2e28-46d7-9089-16a5700d59f6",
   "metadata": {},
   "source": [
    "## Изучение структуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a317358b-cad8-498a-92cc-b7af82822289",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_flow = h5py.File(mx, 'r')\n",
    "col_names = list(mi_flow[list(mi_flow.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef1ee076-cab0-42d3-93cf-8034d39df80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axis0', 'axis1', 'block0_items', 'block0_values']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f9459d1-e42a-4d4c-8962-06b0dd8735f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228942,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['axis0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7540bbea-7d4a-4772-9404-671311b67e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'chr10:100653097-100653634'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['axis0'][145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "104eb067-ebc1-4bc7-baa7-abf793a53c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105942,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['axis1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "266c51db-ddb0-4dd0-ad1e-e313edf2f876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'56390cf1b95e'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['axis1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33e330a5-7d6b-41e7-ae29-6e3d2560e9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228942,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['block0_items'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a81358bd-7b39-44d4-a6e3-9baad2647b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'chr10:100653097-100653634'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['block0_items'][145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4714755-e4ef-48bc-bf2a-a8ffa6930c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105942, 228942)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['block0_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dc9e878-8198-47a8-b66a-5ceda53385b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['block0_values'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4833ea5e-1219-40e1-b28a-0a008b421d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228942,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['block0_values'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7802735-4afd-438e-944f-9243b158adbb",
   "metadata": {},
   "source": [
    "Итак, файл состоит из **названия участка генома, уникального идентификатора клетки, и большой numpy матрицы** являющейся ATAC данными.\n",
    "Строчек в numpy массиве столько же сколько уникальных id клеток, таким образом строчка в матрице является вектором фичей конкретной клетки. Мы подразумеваем что порядок совпадает и сделан без ошибок. Так же у нас есть название для каждого столбца в матрице, указывающее на позицию ATAC фичи, но он полностью совпадает со списком позиций. Информация об участке на днк нам сейчас безполезна. Однако ее тоже можно обрабатывать.\n",
    "\n",
    "**dna_pos:** mi_flow[list(mi_flow.keys())[0]]['axis0'] (список строк в битовом виде)\n",
    "\n",
    "**cell_id:** mi_flow[list(mi_flow.keys())[0]]['axis1'] (список строк в битовом виде)\n",
    "\n",
    "**atac_array:** mi_flow[list(mi_flow.keys())[0]]['block0_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "470c9d58-9d82-4ab9-996b-b97806a75fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_multi_inputs']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mi_flow.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13daad4a-cf6b-4c10-91f9-230610cdf2e1",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73f896fd-25d2-47c3-a3ed-1dcd06d6f646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_multi_targets']\n"
     ]
    }
   ],
   "source": [
    "my_flow = h5py.File(my, 'r')\n",
    "print(list(my_flow.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdc0b1e3-582b-4a4e-9f0d-f9a831106e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(my_flow['train_multi_targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4d66a66-cac6-407e-a43a-76f695467840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axis0', 'axis1', 'block0_items', 'block0_values']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b35aeb65-85e8-44ac-a05d-81f1571363d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ENSG00000121410'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_flow['train_multi_targets']['block0_items'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "760ff4d2-4cc8-42fb-b703-9cf03205fd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ENSG00000121410'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_flow['train_multi_targets']['axis0'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734e74c-6e13-4e4c-b1dd-aa42f3a3ee87",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90205f66-acf6-43d8-8db1-dd755992d0ae",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f116256-c693-42f7-bec2-f27da4c4f78e",
   "metadata": {},
   "source": [
    "# Test new dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41aa9c32-20be-46fd-83c1-c74060f36578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "# не удалять! import hdf5plugin !\n",
    "import hdf5plugin\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a28a06-10ad-474a-8bb1-98fc9d8ff2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSCCDataset(Dataset):\n",
    "    file_types = ['inputs', 'targets']\n",
    "    h5_reserved_names: List[str] = ['train_multi_inputs', 'train_multi_targets', 'train_cite_inputs',\n",
    "                                    'train_cite_targets', 'test_multi_inputs', 'test_cite_inputs']\n",
    "\n",
    "    dataflows = {'cite': {'train': {'inputs': None, 'targets': None},\n",
    "                          'test': {'inputs': None}},\n",
    "                 'multi': {'train': {'inputs': None, 'targets': None},\n",
    "                           'test': {'inputs': None}}}\n",
    "\n",
    "    metadata = None\n",
    "    meta_unique_vals: Dict = {}\n",
    "    metadata_file: str = 'metadata.csv'\n",
    "    meta_transform_names: List[str] = ['day', 'donor', 'cell_type']\n",
    "    meta_names: List[str] = ['day', 'donor', 'cell_type', 'technology']\n",
    "    meta_keys: List[str] = ['cell_id', 'day', 'donor', 'cell_type', 'technology']\n",
    "\n",
    "    col_name: str = 'axis0'\n",
    "    pos_name: str = 'position'\n",
    "    index_name: str = 'cell_id'\n",
    "    cell_id_name: str = \"axis1\"\n",
    "    target_name: str = 'gene_id'\n",
    "    features_name: str = \"block0_values\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset_path: Union[str, Path],\n",
    "                 task: str, mode: str,\n",
    "                 meta_transform: Optional[str] = None,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 target_transform: Optional[Callable] = None):\n",
    "        self.task = task\n",
    "        self.mode = mode\n",
    "        self.data_ids = None\n",
    "        self.data_shapes = None\n",
    "        self.dataset_path = dataset_path\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.meta_transform = meta_transform\n",
    "        # init dataset\n",
    "        self._read_task_dataset(dataset_path)\n",
    "\n",
    "    def _read_metadata(self, path: str) -> pd.DataFrame:\n",
    "        df = pd.read_csv(path, index_col=self.index_name)\n",
    "        for key in self.meta_names:\n",
    "            self.meta_unique_vals[key] = list(df[key].unique())\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _transform_metalabels(self, meta_dict: Dict, cell_id: str) -> Dict:\n",
    "        if self.meta_transform:\n",
    "            if self.meta_transform == 'index':\n",
    "                for key in self.meta_transform_names:\n",
    "                    meta_dict[key] = self.meta_unique_vals[key].index(self.metadata[key][cell_id])\n",
    "            elif self.meta_transform == 'one_hot':\n",
    "                for key in self.meta_transform_names:\n",
    "                    one_hot_vector = np.zeros((len(self.meta_unique_vals[key]),))\n",
    "                    one_hot_vector[self.meta_unique_vals[key].index(self.metadata[key][cell_id])] = 1\n",
    "                    meta_dict[key] = one_hot_vector\n",
    "            else:\n",
    "                raise ValueError(f\"The argument 'meta_transform' can only take values from a list \"\n",
    "                                 f\"['index', 'one_hot', None], but '{self.meta_transform}' was found.\")\n",
    "        else:\n",
    "            meta_dict = {key: self.metadata[key][cell_id] for key in self.meta_names}\n",
    "\n",
    "        return meta_dict\n",
    "\n",
    "    def _get_task_flow(self, folder_path: Path, mode: str, task: str, file_type: str) -> None:\n",
    "        file_name = '_'.join([mode, task, file_type])\n",
    "        print(f\"[ Reading {file_name}.h5 file ... ]\")\n",
    "        f_path = str(folder_path.joinpath(f\"{file_name}.h5\").absolute())\n",
    "        flow, feature_shape = self.get_hdf5_flow(f_path)\n",
    "        # write data in structure\n",
    "        self.dataflows[task][mode][file_type] = flow\n",
    "        self.data_shapes[task][mode][file_type] = feature_shape\n",
    "        print(f\"[ Reading {file_name}.h5 file is complete. ]\")\n",
    "\n",
    "    def _read_task_dataset(self, folder_path: Union[str, Path]) -> None:\n",
    "        self.data_shapes = {self.task: {self.mode: {s: None for s in self.file_types}}}\n",
    "        \n",
    "        if isinstance(folder_path, str):\n",
    "            folder_path = Path(folder_path)\n",
    "        # read metadata file\n",
    "        self.metadata = self._read_metadata(str(folder_path.joinpath(self.metadata_file)))\n",
    "        # read all h5 files\n",
    "        if self.mode == 'train':\n",
    "            for file_type in self.file_types:\n",
    "                self._get_task_flow(folder_path, self.mode, self.task, file_type)\n",
    "        elif self.mode == 'test':\n",
    "            self._get_task_flow(folder_path, self.mode, self.task, self.file_types[0])\n",
    "        else:\n",
    "            raise ValueError(f\"Argument 'mode' can only take values from a list: ['train', 'test'], \"\n",
    "                             f\"but {self.mode} was found.\")\n",
    "\n",
    "        self.data_ids = self._set_data_ids()\n",
    "\n",
    "    def _set_data_ids(self):\n",
    "        feature_flow = self.dataflows[self.task][self.mode]['inputs']\n",
    "        return [x.decode(\"utf-8\") for x in feature_flow[self.cell_id_name]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_ids)\n",
    "\n",
    "    def __getitem__(self, item: int) -> Union[Tuple[torch.Tensor, Dict[str, str]],\n",
    "                                              Tuple[torch.Tensor, torch.Tensor, Dict[str, str]]]:\n",
    "        cell_id = self.data_ids[item]\n",
    "        features = self.dataflows[self.task][self.mode]['inputs']\n",
    "        meta_data = {self.index_name: cell_id, self.pos_name: features[self.col_name][item].decode(\"utf-8\")}\n",
    "        meta_data = self._transform_metalabels(meta_data, cell_id)\n",
    "\n",
    "        x = features[self.features_name][item]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        if self.dataflows[self.task][self.mode].get('targets'):\n",
    "            targets = self.dataflows[self.task][self.mode]['targets']\n",
    "            meta_data[self.target_name] = targets[self.col_name][item].decode(\"utf-8\")\n",
    "            y = targets[self.features_name][item]\n",
    "            if self.target_transform:\n",
    "                y = self.target_transform(y)\n",
    "\n",
    "            return x, y, meta_data\n",
    "        else:\n",
    "            return x, meta_data\n",
    "\n",
    "    def get_hdf5_flow(self, file_path: str):\n",
    "        file_flow = h5py.File(file_path, 'r')\n",
    "\n",
    "        file_keys = list(file_flow.keys())\n",
    "        assert len(file_keys) == 1, AssertionError(f\"Incorrect file format, '{file_path}' file have more than one \"\n",
    "                                                   f\"group: {file_keys}.\")\n",
    "\n",
    "        file_name = file_keys[0]\n",
    "        assert file_name in self.h5_reserved_names, \\\n",
    "            AssertionError(f\"Incorrect file format, group name must be in {self.h5_reserved_names}, \"\n",
    "                           f\"but {file_name} was found.\")\n",
    "\n",
    "        datasets_names = list(file_flow[file_name])\n",
    "        assert self.features_name in datasets_names, AssertionError(f\"Incorrect file format, dataset name \"\n",
    "                                                                    f\"{self.features_name} was not found in hdf5 file \"\n",
    "                                                                    f\"datasets list.\")\n",
    "        assert self.cell_id_name in datasets_names, AssertionError(f\"Incorrect file format, dataset name \"\n",
    "                                                                   f\"{self.cell_id_name} was not found in hdf5 file \"\n",
    "                                                                   f\"datasets list.\")\n",
    "        assert self.col_name in datasets_names, AssertionError(f\"Incorrect file format, dataset name {self.col_name} \"\n",
    "                                                               f\"was not found in hdf5 file datasets list.\")\n",
    "\n",
    "        lines, features_shape = file_flow[file_name][self.features_name].shape\n",
    "\n",
    "        return file_flow[file_name], (lines, features_shape)\n",
    "\n",
    "    def reindex_dataset(self,\n",
    "                        day: Optional[Union[int, List[int]]] = None,\n",
    "                        donor: Optional[Union[int, List[int]]] = None,\n",
    "                        cell_type: Optional[Union[str, List[str]]] = None) -> None:\n",
    "        conditions = []\n",
    "        if (day is not None) and isinstance(day, int):\n",
    "            conditions.append((self.metadata['day'] == day))\n",
    "        elif (day is not None) and isinstance(day, list):\n",
    "            conditions.append((self.metadata['day'].isin(day)))\n",
    "\n",
    "        if (donor is not None) and isinstance(donor, int):\n",
    "            conditions.append((self.metadata['donor'] == donor))\n",
    "        elif (donor is not None) and isinstance(donor, list):\n",
    "            conditions.append((self.metadata['donor'].isin(donor)))\n",
    "\n",
    "        if (cell_type is not None) and isinstance(cell_type, int):\n",
    "            conditions.append((self.metadata['cell_type'] == cell_type))\n",
    "        elif (cell_type is not None) and isinstance(cell_type, list):\n",
    "            conditions.append((self.metadata['cell_type'].isin(cell_type)))\n",
    "\n",
    "        if len(conditions) > 0:\n",
    "            feature_flow = self.dataflows[self.task][self.mode]['inputs']\n",
    "            ids = {x.decode(\"utf-8\") for x in feature_flow[self.cell_id_name]}\n",
    "\n",
    "            final_cond = conditions[0]\n",
    "            if len(conditions) > 1:\n",
    "                for cond in conditions[1:]:\n",
    "                    final_cond &= cond\n",
    "\n",
    "            cond_index = set(self.metadata[final_cond].index)\n",
    "            self.data_ids = list(cond_index & ids)\n",
    "\n",
    "    def reset(self, task: Optional[str] = None, mode: Optional[str] = None):\n",
    "        if task is not None:\n",
    "            self.task = task\n",
    "        if mode is not None:\n",
    "            self.mode = mode\n",
    "\n",
    "        self._read_task_dataset(self.dataset_path)\n",
    "        self.data_ids = self._set_data_ids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e864461-0963-4698-8cae-e0b8932e4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/metadata.csv'\n",
    "\n",
    "# mx = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_multi_inputs.h5'\n",
    "# my = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_multi_targets.h5'\n",
    "# test_my = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/test_multi_inputs.h5'\n",
    "\n",
    "# cx = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_cite_inputs.h5'\n",
    "# cy = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_cite_targets.h5'\n",
    "# test_cy = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/test_cite_inputs.h5'\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "dataset_folder = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ab26315-5737-4cf4-944c-b24f67cc3b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Reading train_cite_inputs.h5 file ... ]\n",
      "[ Reading train_cite_inputs.h5 file is complete. ]\n",
      "[ Reading train_cite_targets.h5 file ... ]\n",
      "[ Reading train_cite_targets.h5 file is complete. ]\n"
     ]
    }
   ],
   "source": [
    "# dataset = SCCDataset(meta_file=meta, features_file=mx, targets_file=my, meta_transform='one_hot')\n",
    "dataset = FSCCDataset(dataset_folder, 'cite', 'train', meta_transform='one_hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb5ae30c-605e-462b-92c6-372f4d9b307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70988"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "566fee38-81d6-4d30-b1c5-4661783b4b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([-2.22691208e-01, -2.52655208e-01,  2.27418989e-01,  3.20292640e+00,\n",
       "         8.51944625e-01,  7.98958540e-01,  1.33187664e+00, -2.11750388e-01,\n",
       "         1.48527831e-01,  8.68058920e-01, -6.94457829e-01,  1.44752157e+00,\n",
       "         1.12667215e+00,  4.21157300e-01,  1.00356808e+01,  2.43488699e-02,\n",
       "         5.31223774e-01, -1.04394287e-01,  1.14951277e+00, -1.19618416e-01,\n",
       "        -1.10979307e+00,  3.15820336e+00,  1.07843137e+00,  1.47565472e+00,\n",
       "         4.69347954e+00, -5.56258976e-01, -3.09214503e-01, -5.44111073e-01,\n",
       "         1.09092668e-01,  1.47972658e-01, -5.45077980e-01,  5.77424824e-01,\n",
       "         3.26725483e-01, -6.73494756e-01, -2.35411733e-01, -4.06153679e-01,\n",
       "         8.13318908e-01,  5.87703705e+00,  8.13279212e-01,  5.66352129e-01,\n",
       "        -8.29805374e-01,  1.88042748e+00, -4.18716282e-01,  2.64636803e+00,\n",
       "        -8.00555229e-01, -4.04821068e-01,  1.34808111e+00,  1.23556578e+00,\n",
       "        -7.95719445e-01,  6.81853890e-01, -2.24865794e-01,  8.37014079e-01,\n",
       "        -4.25393850e-01, -1.96303815e-01,  1.37734437e+00,  1.14256096e+00,\n",
       "         8.36951792e-01,  1.65709853e+00,  2.91397905e+00,  6.95300221e-01,\n",
       "         8.91363978e-01,  4.77302015e-01,  6.98951602e-01,  2.34618917e-01,\n",
       "        -2.07502782e-01, -2.79330313e-02,  2.21742773e+00,  7.93560147e-01,\n",
       "         3.98542166e+00,  1.02467999e-01,  1.22168615e-01,  2.73447067e-01,\n",
       "        -3.27148020e-01,  1.25659275e+00, -6.10459447e-01,  3.25992227e+00,\n",
       "        -5.18694520e-01, -2.04524696e-01,  9.16644812e-01,  1.96326637e+00,\n",
       "        -5.77883303e-01, -2.99346358e-01,  5.28641760e-01,  1.00442910e+00,\n",
       "         9.30799782e-01,  2.77616471e-01,  1.54723310e+00,  1.57696605e+00,\n",
       "         8.53518844e-01,  1.02747703e+00, -5.60062528e-01,  2.45077819e-01,\n",
       "        -2.74987876e-01,  2.52143979e-01,  4.71032023e-01,  7.24591315e-03,\n",
       "         9.04952765e-01,  5.80935049e+00, -4.90710616e-01,  1.34595084e+00,\n",
       "         1.50419950e+00, -2.18015581e-01, -6.88900948e-02, -8.41040611e-01,\n",
       "         1.60624766e+00,  1.08432961e+00,  7.24948525e-01, -1.15711510e-01,\n",
       "         1.80507584e+01,  1.89041042e+00,  2.84945631e+00,  3.25132537e+00,\n",
       "        -8.96184921e-01,  3.53276283e-01,  4.32447374e-01, -1.67318672e-01,\n",
       "         7.54840612e-01,  2.17083469e-01, -3.08684677e-01,  5.62527514e+00,\n",
       "         1.24689794e+00,  1.02261138e+00,  5.26278675e-01, -2.27150038e-01,\n",
       "        -1.07373536e+00,  3.44825804e-01,  1.11673415e+00,  2.43960667e+00,\n",
       "        -5.79085827e-01,  1.46458828e+00,  5.91509938e-01,  3.76812196e+00,\n",
       "         4.43002671e-01, -4.16017979e-01, -8.63863081e-02,  1.39519334e+00,\n",
       "         2.67658854e+00,  1.84915793e+00,  7.34386921e+00,  3.90299082e-01],\n",
       "       dtype=float32),\n",
       " {'cell_id': '52907cde6bda',\n",
       "  'position': 'ENSG00000146109_ABT1',\n",
       "  'day': array([0., 0., 0., 1., 0.]),\n",
       "  'donor': array([0., 1., 0., 0.]),\n",
       "  'cell_type': array([0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       "  'gene_id': 'CD81'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d149be0-fbd3-4c14-941f-681096c59e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day': [3, 4, 7, 2, 10],\n",
       " 'donor': [27678, 32606, 13176, 31800],\n",
       " 'cell_type': ['MasP', 'MkP', 'NeuP', 'HSC', 'EryP', 'MoP', 'BP', 'hidden'],\n",
       " 'technology': ['citeseq', 'multiome']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.meta_unique_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d7167a-2e54-4c99-b9e1-26b1bcc41ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day', 'donor', 'cell_type', 'technology']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.meta_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b286618b-a6fb-4124-ac25-5e8d57efeb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cite': {'test': {'inputs': (48203, 22050), 'targets': None}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75757fab-4c22-45d2-9bf7-eeace4d35e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reindex_dataset(day=3, donor=[27678, 32606, 13176])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "468a945e-28d3-4ab3-9ddc-52042fb54211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6488"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dba5326a-8c04-49e0-917b-8d0a9dcbe579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Reading train_multi_inputs.h5 file ... ]\n",
      "[ Reading train_multi_inputs.h5 file is complete. ]\n",
      "[ Reading train_multi_targets.h5 file ... ]\n",
      "[ Reading train_multi_targets.h5 file is complete. ]\n"
     ]
    }
   ],
   "source": [
    "dataset.reset('multi', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaaee6e1-c18b-4302-8f87-f0efeb30ad87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105942"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10db060-f8ea-419b-ae36-27ea1a9df42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
