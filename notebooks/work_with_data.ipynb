{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d51a7dd-f1f8-4447-9680-90b61ff9d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import h5py\n",
    "# не удалять! import hdf5plugin !\n",
    "import hdf5plugin\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50983244-4119-4536-9d8b-3404237f5854",
   "metadata": {},
   "source": [
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f238e7e9-9416-4999-95fb-9d85ba6736ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/metadata.csv'\n",
    "df_meta = pd.read_csv(meta_file, index_col='cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcae7984-d597-4764-98d1-d53638b3a550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>donor</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>technology</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e0dde41ed6f2</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>MasP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25b1de7f18f6</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>MkP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59e175749a4c</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>MkP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc43f415f240</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>NeuP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cf6cb48a1aca</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>HSC</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d03cdc2150c</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>EryP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ed27b16f6b29</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>NeuP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20a5293b5a5f</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>NeuP</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9c110ee995b5</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>HSC</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655fb0bf81df</th>\n",
       "      <td>3</td>\n",
       "      <td>27678</td>\n",
       "      <td>HSC</td>\n",
       "      <td>citeseq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              day  donor cell_type technology\n",
       "cell_id                                      \n",
       "e0dde41ed6f2    3  27678      MasP    citeseq\n",
       "25b1de7f18f6    3  27678       MkP    citeseq\n",
       "59e175749a4c    3  27678       MkP    citeseq\n",
       "cc43f415f240    3  27678      NeuP    citeseq\n",
       "cf6cb48a1aca    3  27678       HSC    citeseq\n",
       "7d03cdc2150c    3  27678      EryP    citeseq\n",
       "ed27b16f6b29    3  27678      NeuP    citeseq\n",
       "20a5293b5a5f    3  27678      NeuP    citeseq\n",
       "9c110ee995b5    3  27678       HSC    citeseq\n",
       "655fb0bf81df    3  27678       HSC    citeseq"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "599a3d0f-ec1b-4dda-aa8e-acfe6289fb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119191\n",
      "['e0dde41ed6f2', '25b1de7f18f6', '59e175749a4c', 'cc43f415f240', 'cf6cb48a1aca', '7d03cdc2150c', 'ed27b16f6b29', '20a5293b5a5f', '9c110ee995b5', '655fb0bf81df']\n"
     ]
    }
   ],
   "source": [
    "ids = list(df_meta[df_meta['technology'] == 'citeseq'].index)\n",
    "print(len(ids))\n",
    "print(ids[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde6280-6066-44fc-8aa5-dfbe66f8a887",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21986a06-adaf-4979-9e30-bc4e8852d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ids = pd.read_csv('/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/evaluation_ids.csv', index_col='cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292d1867-1213-445a-8b0a-78f831307426",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_multi_inputs.h5'\n",
    "my = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_multi_targets.h5'\n",
    "cx = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_cite_inputs.h5'\n",
    "cy = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_cite_targets.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a00cefa-c1b3-4ad3-b1f8-e555b19efa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_my = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/test_multi_inputs.h5'\n",
    "test_cy = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/test_cite_inputs.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a5d90e-922c-4141-91d4-d29d7bbe15c8",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b03b85f-2e28-46d7-9089-16a5700d59f6",
   "metadata": {},
   "source": [
    "## Изучение структуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a317358b-cad8-498a-92cc-b7af82822289",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_flow = h5py.File(mx, 'r')\n",
    "col_names = list(mi_flow[list(mi_flow.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef1ee076-cab0-42d3-93cf-8034d39df80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axis0', 'axis1', 'block0_items', 'block0_values']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f9459d1-e42a-4d4c-8962-06b0dd8735f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228942,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['axis0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7540bbea-7d4a-4772-9404-671311b67e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'chr10:100653097-100653634'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['axis0'][145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "104eb067-ebc1-4bc7-baa7-abf793a53c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105942,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['axis1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "266c51db-ddb0-4dd0-ad1e-e313edf2f876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'56390cf1b95e'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['axis1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33e330a5-7d6b-41e7-ae29-6e3d2560e9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228942,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['block0_items'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a81358bd-7b39-44d4-a6e3-9baad2647b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'chr10:100653097-100653634'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['block0_items'][145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4714755-e4ef-48bc-bf2a-a8ffa6930c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105942, 228942)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['block0_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dc9e878-8198-47a8-b66a-5ceda53385b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['block0_values'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4833ea5e-1219-40e1-b28a-0a008b421d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228942,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_flow[list(mi_flow.keys())[0]]['block0_values'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7802735-4afd-438e-944f-9243b158adbb",
   "metadata": {},
   "source": [
    "Итак, файл состоит из **названия участка генома, уникального идентификатора клетки, и большой numpy матрицы** являющейся ATAC данными.\n",
    "Строчек в numpy массиве столько же сколько уникальных id клеток, таким образом строчка в матрице является вектором фичей конкретной клетки. Мы подразумеваем что порядок совпадает и сделан без ошибок. Так же у нас есть название для каждого столбца в матрице, указывающее на позицию ATAC фичи, но он полностью совпадает со списком позиций. Информация об участке на днк нам сейчас безполезна. Однако ее тоже можно обрабатывать.\n",
    "\n",
    "**dna_pos:** mi_flow[list(mi_flow.keys())[0]]['axis0'] (список строк в битовом виде)\n",
    "\n",
    "**cell_id:** mi_flow[list(mi_flow.keys())[0]]['axis1'] (список строк в битовом виде)\n",
    "\n",
    "**atac_array:** mi_flow[list(mi_flow.keys())[0]]['block0_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "470c9d58-9d82-4ab9-996b-b97806a75fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_multi_inputs']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mi_flow.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13daad4a-cf6b-4c10-91f9-230610cdf2e1",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73f896fd-25d2-47c3-a3ed-1dcd06d6f646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_multi_targets']\n"
     ]
    }
   ],
   "source": [
    "my_flow = h5py.File(my, 'r')\n",
    "print(list(my_flow.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdc0b1e3-582b-4a4e-9f0d-f9a831106e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(my_flow['train_multi_targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4d66a66-cac6-407e-a43a-76f695467840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['axis0', 'axis1', 'block0_items', 'block0_values']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b35aeb65-85e8-44ac-a05d-81f1571363d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ENSG00000121410'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_flow['train_multi_targets']['block0_items'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "760ff4d2-4cc8-42fb-b703-9cf03205fd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ENSG00000121410'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_flow['train_multi_targets']['axis0'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734e74c-6e13-4e4c-b1dd-aa42f3a3ee87",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90205f66-acf6-43d8-8db1-dd755992d0ae",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f116256-c693-42f7-bec2-f27da4c4f78e",
   "metadata": {},
   "source": [
    "# Test new dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41aa9c32-20be-46fd-83c1-c74060f36578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "# не удалять! import hdf5plugin !\n",
    "import hdf5plugin\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "36a28a06-10ad-474a-8bb1-98fc9d8ff2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalSCCDataset(Dataset):\n",
    "    file_types = ['inputs', 'targets']\n",
    "    h5_reserved_names: List[str] = ['train_multi_inputs', 'train_multi_targets', 'train_cite_inputs',\n",
    "                                    'train_cite_targets', 'test_multi_inputs', 'test_cite_inputs']\n",
    "\n",
    "    dataflows = {'cite': {'train': {'inputs': None, 'targets': None},\n",
    "                          'test': {'inputs': None}},\n",
    "                 'multi': {'train': {'inputs': None, 'targets': None},\n",
    "                           'test': {'inputs': None}}}\n",
    "    data_shapes = {'cite': {'train': {'inputs': None, 'targets': None},\n",
    "                            'test': {'inputs': None}},\n",
    "                   'multi': {'train': {'inputs': None, 'targets': None},\n",
    "                             'test': {'inputs': None}}}\n",
    "\n",
    "    metadata = None\n",
    "    meta_unique_vals: Dict = {}\n",
    "    metadata_file: str = 'metadata.csv'\n",
    "    meta_transform_names: List[str] = ['day', 'donor', 'cell_type']\n",
    "    meta_names: List[str] = ['day', 'donor', 'cell_type', 'technology']\n",
    "    meta_keys: List[str] = ['cell_id', 'day', 'donor', 'cell_type', 'technology']\n",
    "\n",
    "    col_name: str = 'axis0'\n",
    "    pos_name: str = 'position'\n",
    "    index_name: str = 'cell_id'\n",
    "    cell_id_name: str = \"axis1\"\n",
    "    target_name: str = 'gene_id'\n",
    "    features_name: str = \"block0_values\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset_path: Union[str, Path],\n",
    "                 task: str, mode: str,\n",
    "                 meta_transform: Optional[str] = None,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 target_transform: Optional[Callable] = None):\n",
    "        self.task = task\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.meta_transform = meta_transform\n",
    "        # -----------------------------------------------------\n",
    "        self.read_task_dataset(dataset_path, task, mode)\n",
    "\n",
    "    def read_metadata(self, path: str) -> pd.DataFrame:\n",
    "        df = pd.read_csv(path, index_col=self.index_name)\n",
    "        for key in self.meta_names:\n",
    "            self.meta_unique_vals[key] = list(df[key].unique())\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform_metalabels(self, meta_dict: Dict, cell_id: str) -> Dict:\n",
    "        if self.meta_transform:\n",
    "            if self.meta_transform == 'index':\n",
    "                for key in self.meta_transform_names:\n",
    "                    meta_dict[key] = self.meta_unique_vals[key].index(self.metadata[key][cell_id])\n",
    "            elif self.meta_transform == 'one_hot':\n",
    "                for key in self.meta_transform_names:\n",
    "                    one_hot_vector = np.zeros((len(self.meta_unique_vals[key]),))\n",
    "                    one_hot_vector[self.meta_unique_vals[key].index(self.metadata[key][cell_id])] = 1\n",
    "                    meta_dict[key] = one_hot_vector\n",
    "            else:\n",
    "                raise ValueError(f\"The argument 'meta_transform' can only take values from a list \"\n",
    "                                 f\"['index', 'one_hot', None], but '{self.meta_transform}' was found.\")\n",
    "        else:\n",
    "            meta_dict = {key: self.metadata[key][cell_id] for key in self.meta_names}\n",
    "\n",
    "        return meta_dict\n",
    "\n",
    "    def get_hdf5_flow(self, file_path: str):\n",
    "        file_flow = h5py.File(file_path, 'r')\n",
    "\n",
    "        file_keys = list(file_flow.keys())\n",
    "        assert len(file_keys) == 1, AssertionError(f\"Incorrect file format, '{file_path}' file have more than one \"\n",
    "                                                   f\"group: {file_keys}.\")\n",
    "\n",
    "        file_name = file_keys[0]\n",
    "        assert file_name in self.h5_reserved_names, \\\n",
    "            AssertionError(f\"Incorrect file format, group name must be in {self.h5_reserved_names}, \"\n",
    "                           f\"but {file_name} was found.\")\n",
    "\n",
    "        datasets_names = list(file_flow[file_name])\n",
    "        assert self.features_name in datasets_names, AssertionError(f\"Incorrect file format, dataset name \"\n",
    "                                                                    f\"{self.features_name} was not found in hdf5 file \"\n",
    "                                                                    f\"datasets list.\")\n",
    "        assert self.cell_id_name in datasets_names, AssertionError(f\"Incorrect file format, dataset name \"\n",
    "                                                                   f\"{self.cell_id_name} was not found in hdf5 file \"\n",
    "                                                                   f\"datasets list.\")\n",
    "        assert self.col_name in datasets_names, AssertionError(f\"Incorrect file format, dataset name {self.col_name} \"\n",
    "                                                               f\"was not found in hdf5 file datasets list.\")\n",
    "\n",
    "        lines, features_shape = file_flow[file_name][self.features_name].shape\n",
    "\n",
    "        return file_flow[file_name], (lines, features_shape)\n",
    "\n",
    "    def get_task_flow(self, folder_path: Path, mode: str, task: str, file_type: str) -> None:\n",
    "        file_name = '_'.join([mode, task, file_type])\n",
    "        print(f\"[ Reading {file_name}.h5 file ... ]\")\n",
    "        f_path = str(folder_path.joinpath(f\"{file_name}.h5\").absolute())\n",
    "        flow, feature_shape = self.get_hdf5_flow(f_path)\n",
    "        # write data in structure\n",
    "        self.dataflows[task][mode][file_type] = flow\n",
    "        self.data_shapes[task][mode][file_type] = feature_shape\n",
    "        print(f\"[ Reading {file_name}.h5 file is complete. ]\")\n",
    "\n",
    "    def read_task_dataset(self, folder_path: Union[str, Path], task: str, mode: str) -> None:\n",
    "        if isinstance(folder_path, str):\n",
    "            folder_path = Path(folder_path)\n",
    "        # read metadata file\n",
    "        self.metadata = self.read_metadata(str(folder_path.joinpath(self.metadata_file)))\n",
    "        # read all h5 files\n",
    "        if mode == 'train':\n",
    "            for file_type in self.file_types:\n",
    "                self.get_task_flow(folder_path, mode, task, file_type)\n",
    "        elif mode == 'test':\n",
    "            self.get_task_flow(folder_path, mode, task, self.file_types[0])\n",
    "        else:\n",
    "            raise ValueError(f\"Argument 'mode' can only take values from a list: ['train', 'test'], \"\n",
    "                             f\"but {mode} was found.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_shapes[self.task][self.mode]['inputs'][0]\n",
    "\n",
    "    def __getitem__(self, item: int) -> Union[Tuple[torch.Tensor, Dict[str, str]],\n",
    "                                              Tuple[torch.Tensor, torch.Tensor, Dict[str, str]]]:\n",
    "        features = self.dataflows[self.task][self.mode]['inputs']\n",
    "        cell_id = features[self.cell_id_name][item].decode(\"utf-8\")\n",
    "        meta_data = {self.index_name: cell_id, self.pos_name: features[self.col_name][item].decode(\"utf-8\")}\n",
    "        meta_data = self.transform_metalabels(meta_data, cell_id)\n",
    "\n",
    "        x = features[self.features_name][item]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        if self.dataflows[self.task][self.mode].get('targets'):\n",
    "            targets = self.dataflows[self.task][self.mode]['targets']\n",
    "            meta_data[self.target_name] = targets[self.col_name][item].decode(\"utf-8\")\n",
    "            y = targets[self.features_name][item]\n",
    "            if self.target_transform:\n",
    "                y = self.target_transform(y)\n",
    "\n",
    "            return x, y, meta_data\n",
    "        else:\n",
    "            return x, meta_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e864461-0963-4698-8cae-e0b8932e4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/metadata.csv'\n",
    "\n",
    "# mx = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_multi_inputs.h5'\n",
    "# my = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_multi_targets.h5'\n",
    "# test_my = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/test_multi_inputs.h5'\n",
    "\n",
    "# cx = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_cite_inputs.h5'\n",
    "# cy = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/train_cite_targets.h5'\n",
    "# test_cy = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/test_cite_inputs.h5'\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "dataset_folder = '/home/mks/PycharmProjects/multimodal_single_cell_integration/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8ab26315-5737-4cf4-944c-b24f67cc3b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Reading train_multi_inputs.h5 file ... ]\n",
      "[ Reading train_multi_inputs.h5 file is complete. ]\n",
      "[ Reading train_multi_targets.h5 file ... ]\n",
      "[ Reading train_multi_targets.h5 file is complete. ]\n"
     ]
    }
   ],
   "source": [
    "# dataset = SCCDataset(meta_file=meta, features_file=mx, targets_file=my, meta_transform='one_hot')\n",
    "dataset = GlobalSCCDataset(dataset_folder, 'multi', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cb5ae30c-605e-462b-92c6-372f4d9b307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105942"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "566fee38-81d6-4d30-b1c5-4661783b4b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.      , 0.      , 0.      , ..., 0.      , 0.      , 5.354978],\n",
       "       dtype=float32),\n",
       " {'day': 2,\n",
       "  'donor': 32606,\n",
       "  'cell_type': 'HSC',\n",
       "  'technology': 'multiome',\n",
       "  'gene_id': 'ENSG00000097007'})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8d149be0-fbd3-4c14-941f-681096c59e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day': [3, 4, 7, 2, 10],\n",
       " 'donor': [27678, 32606, 13176, 31800],\n",
       " 'cell_type': ['MasP', 'MkP', 'NeuP', 'HSC', 'EryP', 'MoP', 'BP', 'hidden'],\n",
       " 'technology': ['citeseq', 'multiome']}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.meta_unique_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0d7167a-2e54-4c99-b9e1-26b1bcc41ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day', 'donor', 'cell_type', 'technology']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.meta_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b286618b-a6fb-4124-ac25-5e8d57efeb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cite': {'train': {'inputs': None, 'targets': None},\n",
       "  'test': {'inputs': None}},\n",
       " 'multi': {'train': {'inputs': (105942, 228942), 'targets': (105942, 23418)},\n",
       "  'test': {'inputs': None}}}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea2eb1a-f014-46ff-926e-cf3c2dfe8d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72268db-d9a4-4cde-82da-87f597903825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
